# Navigating Threats in Federated Recommender	Systems: A Survey of Poisoning Attacks and Defense Strategies

In our mission to advance the field of privacy-preserving and responsible recommender systems (PPRS), we understand the importance of practical tools and resources that aid researchers and practitioners in their work. As part of our commitment to the community, we've curated an extensive collection of toolkits, codebases, and recent repositories spanning key technologies such as Federated Learning, Blockchain, Differential Privacy, and other aspects of responsible recommender systems. Our collection serves a valuable resource for those eager to explore, experiment, and contribute to the development of robust PPRS solutions.

## Responsibility Aspects (Fairness, Privacy, Security): 

In line with our commitment to empowering researchers and practitioners in the domain of privacy-preserving and responsible recommender systems, our repository offers a curated selection of versatile toolkits and open-source repositories. These resources cater to various stages of recommender system development, facilitating the creation, experimentation, regeneration of results, and evaluation across diverse datasets. Specifically tailored to prioritize responsibility aspects, including fairness, privacy, security, attack resilience, and accountability within recommender systems, the table below showcases a range of toolkits meticulously designed to address these crucial dimensions.
#### Evaluation Frameworks 
| Tile                                   | Affiliations                                                                            | Venue Year | Material                                                                                                                 |
|----------------------------------------|-----------------------------------------------------------------------------------------|-------|--------------------------------------------------------------------------------------------------------------------------|
|	Surprise	|	Columbia University, USA	|	2023	|	[Paper](https://doi.org/10.21105/joss.02174), [Code](https://surpriselib.com/)	|
|	Microsoft Recommender	|	Micrrosoft UK	|	2023	|	[Paper](https://dl.acm.org/doi/abs/10.1145/3366424.3382692), [Code](https://github.com/microsoft/recommenders)	|
|	ELLIOT	|	SisInfLab Group	|	2023	|	[Paper](https://doi.org/10.1145/3404835.3463245), [Code](https://github.com/sisinflab/elliot)	|


#### Practical Implementations
| Tile                                   | Affiliations                                                                            | Venue Year | Material |
|----------------------------------------|-----------------------------------------------------------------------------------------|-------|--------------------------------------------------------------------------------------------------------------------------|
|	Calibration Matters: Tackling Maximization Bias in Large-Scale Advertising Recommendation Systems	|	Carnegie Mellon University	|	ICLR 2023	|	[Paper](https://arxiv.org/pdf/2205.09809.pdf), [Code](https://github.com/tofuwen/VAD)	|


## Federated Learning Toolkit: 
We explored a range of open-source libraries and codebases designed to implement federated learning techniques. Whether you're interested in preserving user privacy, enhancing recommendation performance, or both, these resources provide a foundation to build upon.
| Tile                                   | Affiliations                                                                            | Venue Year | Material                                                                                                                 |
|----------------------------------------|-----------------------------------------------------------------------------------------|-------|--------------------------------------------------------------------------------------------------------------------------|

|	Untargeted Embedding Attacks on FedRec	|	University of Science and Technology of China	|	2023	|	[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/25611), [Code](https://github.com/yflyl613/FedRec)	|

|	RAIFLE: attacks on Federated Learning with Adversarial Data Manipulation	|	University of Massachusetts Amherst	|	2025	|	[Paper](https://arxiv.org/pdf/2310.19163), [Code](https://github.com/dzungvpham/raifle)	|

|	Cocktail Party Attack	|	Meta AI	|	2023	|	[Paper](https://proceedings.mlr.press/v202/kariyappa23a/kariyappa23a.pdf), [Code](https://github.com/facebookresearch/cocktail_party_attack)	|

|	Focused Flip: Vulnerability of Backdoor Defenses for Federated Learning	|	Pennsylvania State University	|	2023	|	[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/26393), [Code](https://github.com/jinghuichen/Focused-Flip-Federated-Backdoor-Attack)	|

|	Untargeted Attack on Federated News Recommendation	|	University of Science
and Technology of China	|	2023	|	[Paper](https://dl.acm.org/doi/pdf/10.1145/3580305.3599923), [Code](https://github.com/yjw1029/UA-FedRec)	|



